{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we analyse the Seattle AirBnB dataset. \n",
    "The data is available at: https://www.kaggle.com/airbnb/seattle\n",
    "\n",
    "The motivation of the analysis is to understand the various factors that determine the price of any listing, understand how the prices in the listings vary through the year and the neighborhoods in Seattle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the CRISP-DM (Cross-Industry Standard Process for Data Mining) methodology, which consists of the following steps:   \n",
    "\n",
    "    1. Business Understanding\n",
    "    2. Data Understanding \n",
    "    3. Prepare Data\n",
    "    4. Data Modeling \n",
    "    5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to understand a few insights from the data:  \n",
    " \n",
    "    1. Are there price variations within the year? Which months are most expensive and which are not?  \n",
    "    \n",
    "    2. How are the prices of properties distributed across the neighborhoods?\n",
    "    \n",
    "    3. Which are the important factors for determining the price of a property? Can we model this?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings = pd.read_csv('./listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListingsColumns = ['id','host_id','host_since','host_response_time','host_response_rate', \\\n",
    "                   'host_acceptance_rate','host_is_superhost', 'host_identity_verified', \\\n",
    "                   'neighbourhood_group_cleansed', 'property_type','room_type','accommodates','bathrooms',\\\n",
    "                   'bedrooms','guests_included','minimum_nights','review_scores_rating','reviews_per_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings = dfListings[ListingsColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender = pd.read_csv('./calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Number of hosts and number of listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_hosts = dfListings['host_id'].nunique()\n",
    "no_listings = dfListings.shape[0]\n",
    "\n",
    "print(\"Number of hosts = {} & number of listings in Seattle = {}\".format(no_hosts,no_listings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender['date'] = pd.to_datetime(dfCalender['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindate = dfCalender['date'].min()\n",
    "maxdate = dfCalender['date'].max()\n",
    "print(\"Data Duration: {} to {}\".format(mindate,maxdate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatedListings = dfListings.duplicated().sum()\n",
    "\n",
    "print(\"Duplicated Listings Rows = {}\".format(duplicatedListings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatedCalender = dfCalender.duplicated().sum()\n",
    "\n",
    "print(\"Duplicated Calender Dataset Rows = {}\".format(duplicatedCalender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Feature Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. Drop calender data without price values\n",
    "Since price is the target variable which we will be predicting later,we will require data with price values given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Change \"price\" to float, and \"available\" to boolean in Calender data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender.price = dfCalender.price.str.replace('$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender.price = dfCalender.price.str.replace(',','').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender['available'].replace({'t':1,'f':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCalender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Listings Data : Change \"host_response_rate\", \"host_acceptance_rate\" to float, and \"host_is_superhost\" ,\" host_identity_verified\"\t to boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings['host_acceptance_rate'] = dfListings['host_acceptance_rate'].str.replace('%','').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings['host_response_rate'] = dfListings['host_response_rate'].str.replace('%','').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings['host_is_superhost'].replace({'f':0,'t':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings['host_identity_verified'].replace({'f':0,'t':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Correlation of Price with various features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. Combine the dataframes to capture price in conjunction with other variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListings.rename(columns={'id':'listing_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined = pd.merge(dfListings,dfCalender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Extract month and year from date and drop date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined['month'] = dfCombined['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined['year'] = dfCombined['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined.drop(['date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Convert host_since to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined['host_since'] = pd.to_datetime(dfCombined['host_since'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining all of the above in a function\n",
    "def clean_data(dfcalender,dflistings):\n",
    "    '''\n",
    "    Clean up dfcalender and dflistings data and combine them into a single dataframe. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfcalender (dataframe): The dataframe containing price data per day of each listing.\n",
    "    dflistings (dataframe): The dataframe containing each listing's details and various details about the host.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    dfcombined (dataframe): The cleaned up and combined dataframe used for modeling in the later steps. \n",
    "    '''\n",
    "\n",
    "    #remove duplicate entries\n",
    "    dfcalender.drop_duplicates(inplace=True)\n",
    "    dflistings.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #remove dfcalender values with missing price column\n",
    "    dfcalender.dropna(inplace=True)\n",
    "    \n",
    "    # change \"price\" to float, and \"available\" to boolean in Calender data\n",
    "    dfcalender.price = dfcalender.price.str.replace('$','')\n",
    "    dfcalender.price = dfcalender.price.str.replace(',','').astype('float')\n",
    "    dfcalender['available'].replace({'t':1,'f':0},inplace=True)\n",
    "    \n",
    "    #Listings Data : Change \"host_response_rate\", \"host_acceptance_rate\" to float,\n",
    "    # and \"host_is_superhost\" ,\" host_identity_verified\" to boolean)\n",
    "    dflistings['host_acceptance_rate'] = dflistings['host_acceptance_rate'].str.replace('%','').astype('float')\n",
    "    dflistings['host_response_rate'] = dflistings['host_response_rate'].str.replace('%','').astype('float')\n",
    "    \n",
    "    dflistings['host_is_superhost'].replace({'f':0,'t':1},inplace=True)\n",
    "    dflistings['host_identity_verified'].replace({'f':0,'t':1},inplace=True)\n",
    "    \n",
    "    #combine the dataframes\n",
    "    dflistings.rename(columns={'id':'listing_id'},inplace=True)\n",
    "    dfcalender['date'] = pd.to_datetime(dfcalender['date'])\n",
    "    dfcombined = pd.merge(dflistings,dfcalender)\n",
    "    \n",
    "\n",
    "    dfcombined['month'] = dfcombined['date'].dt.month\n",
    "    dfcombined['year'] = dfcombined['date'].dt.year\n",
    "    dfcombined.drop(['date'],axis=1,inplace=True)\n",
    "    \n",
    "    # convert host_since to datetime object\n",
    "    dfcombined['host_since'] = pd.to_datetime(dfcombined['host_since'],errors='coerce')\n",
    "    \n",
    "    return dfcombined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test this function by comparing its output with our preprocessed dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflistings = pd.read_csv('./listings.csv')\n",
    "dfcalender = pd.read_csv('./calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListingsColumns = ['id','host_id','host_since','host_response_time','host_response_rate', \\\n",
    "                   'host_acceptance_rate','host_is_superhost', 'host_identity_verified', \\\n",
    "                   'neighbourhood_group_cleansed', 'property_type','room_type','accommodates','bathrooms',\\\n",
    "                   'bedrooms','guests_included','minimum_nights','review_scores_rating','reviews_per_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflistings = dflistings[ListingsColumns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined2 = clean_data(dfcalender,dflistings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined2.equals(dfCombined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Awesome. Now we can go ahead with answering the questions we had stated in the first section, through some plots and a model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = dfCombined.select_dtypes(include=['number']).drop(['listing_id','host_id','available'],axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Feature Correlation Matrix');\n",
    "sns.heatmap(corrmat,\n",
    "            annot=True,\n",
    "            square=True,\n",
    "            fmt = '.2f'\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, property parameters related to the size and broader ameneties (number of bedrooms, bathrooms, number of people the property accommodates) determine the price to a large extent and even features like time of the year (month), review_scores, and host related features like host_identity_verified, and host_is_superhost determine the price of the property to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Number of listings by month for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(dfCombined[dfCombined['year'] == 2016].groupby(['month'])['listing_id'].nunique());\n",
    "plt.title('Number of listings per month (2016)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summer (July) has lower listings than other months "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Price Variation by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(dfCombined.groupby(['month'])['price'].mean());\n",
    "plt.title('Average price per month');\n",
    "plt.xlabel('Month');\n",
    "plt.ylabel('Price ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question1: Are there price variations within the year? Which months are most expensive and which are not?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summer (July) also has the highest average rates than other parts of the year, and to a lesser extent December as well indicating holiday season to be expensive time to visit Seattle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Prices against neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = dfCombined.neighbourhood_group_cleansed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNeighborhood = pd.DataFrame(dfCombined.groupby(['neighbourhood_group_cleansed','month'])['price'].mean().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20,10))\n",
    "ax = plt.subplot()\n",
    "for neighborhood in neighborhoods:\n",
    "    ax.plot(dfNeighborhood[dfNeighborhood['neighbourhood_group_cleansed'] == neighborhood]['month'],\n",
    "            dfNeighborhood[dfNeighborhood['neighbourhood_group_cleansed'] == neighborhood]['price'],\n",
    "            label = neighborhood\n",
    "           )\n",
    "ax.legend(loc = 'upper right')\n",
    "plt.xlabel('Month');\n",
    "plt.ylabel('Price (in $)');\n",
    "plt.title('Prices of listings in various months of 2016 by neighborhood');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question2 :  How are the prices of properties distributed across the neighborhoods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Downtown has the highest prices and almost all neighborhoods have higher prices in summer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move to the final part of the analysis: Understanding which features impact prices and building a model to predict prices to answer the last question.\n",
    "\n",
    "### Question 3: Which are the important factors for determining the price of a property? Can we model this?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build the following models:  \n",
    "    1. Linear Regression Model  \n",
    "    2. Lasso Regression Model  \n",
    "    3. Random Forest Regression Model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We now make dummy variables of the categorical columns of interest and append them to the combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedCat =  pd.get_dummies(dfCombined.select_dtypes(['object'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedCat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal = pd.concat([dfCombined.select_dtypes(['number']),dfCombinedCat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_with_missing_data = dfCombinedFinal.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_with_missing_data[col_with_missing_data > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy: \n",
    "-  **host_acceptance_rate, review_scores_rating, reviews_per_month, host_response_rate**: We fill the missing entries for these columns using a statistic (median,mode) since these columns are not very highly correlating to the output.   <br/><br/>\n",
    "\n",
    "- **bathrooms, bedrooms**: We discard rows with these features missing, as these are highly correlating to the output, thus it would be important to have these details for a prediction.  <br/><br/>\n",
    "\n",
    "- **host_is_superhost,host_identity_verified**: Since very little data doesnt have this information, we can skip the entries that dont have these inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['host_acceptance_rate'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['host_acceptance_rate'].fillna(dfCombinedFinal['host_acceptance_rate'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['review_scores_rating'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['review_scores_rating'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['review_scores_rating'].fillna(dfCombinedFinal['review_scores_rating'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['reviews_per_month'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['reviews_per_month'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['reviews_per_month'].fillna(dfCombinedFinal['reviews_per_month'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['host_response_rate'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['host_response_rate'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal['host_response_rate'].fillna(dfCombinedFinal['reviews_per_month'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_with_missing_data = dfCombinedFinal.isna().mean().sort_values(ascending=False)\n",
    "col_with_missing_data[col_with_missing_data > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We drop the remaining rows with NA values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a function for this now and test the output with the dfCombinedFinal dataframe output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(df):\n",
    "    '''\n",
    "    Parameters\n",
    "    --------------\n",
    "    df : Input dataframe with missing values in certain columns \n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    df : Output dataframe with either missing values imputed or dropped. \n",
    "    \n",
    "    '''\n",
    "    df['host_acceptance_rate'].fillna(df['host_acceptance_rate'].mode()[0],inplace=True)\n",
    "    df['review_scores_rating'].fillna(df['review_scores_rating'].median(),inplace=True)\n",
    "    df['reviews_per_month'].fillna(df['reviews_per_month'].mode()[0],inplace=True)\n",
    "    df['host_response_rate'].fillna(df['reviews_per_month'].median(),inplace=True)\n",
    "    \n",
    "    col_with_missing_data = df.isna().mean().sort_values(ascending=False)\n",
    "    col_with_missing_data[col_with_missing_data > 0]\n",
    "    \n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Clean up dfcalender and dflistings data and combine them into a single dataframe. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfcalender (dataframe): The dataframe containing price data per day of each listing.\n",
    "    dflistings (dataframe): The dataframe containing each listing's details and various details about the host.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    dfcombined (dataframe): The cleaned up and combined dataframe used for modeling in the later steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([dfCombined.select_dtypes(['number']),dfCombinedCat],axis=1)\n",
    "dfCombinedFinal2 = handle_missing_data(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedFinal2.equals(dfCombinedFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Awesome. Now that our data cleaning function is also set, we move towards splitting the data into features and output column to feed to the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We finally have 54 features in our training data which we will use to build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfCombinedFinal.drop(['listing_id','host_id','price'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfCombinedFinal['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegModel = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegModel.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Regression Model: Train Score = {:.2f}\".format(LinRegModel.score(X_train_scaled,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Regression Model: Test Score = {:.2f}\".format(LinRegModel.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegModel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLinCoefs = pd.DataFrame({'columns':X_train.columns,\n",
    "              'Coefficient':LinRegModel.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLinCoefs.sort_values(by='Coefficient',ascending=False).reset_index().drop(['index'],axis=1)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unfortunately the coefficient weights dont seem to be matching to expected important variables. Since Linear model is unable to deduct any features away and also cannot capture correlations between features thus the coefficients will be a bit unexplainable. \n",
    "\n",
    "* We now move to a slightly better linear regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model 2: Lasso Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoModel = Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoModel.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso Regression Model: Train Score = {:.2f}\".format(LassoModel.score(X_train_scaled,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso Regression Model: Test Score = {:.2f}\".format(LassoModel.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoModel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLassoCoefs = pd.DataFrame({'columns':X_train.columns,\n",
    "              'Coefficient':LassoModel.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLassoCoefs.sort_values(by='Coefficient',ascending=False).reset_index().drop(['index'],axis=1)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already see sensible features with higher weights so even though the scores of linear and lasso regression were not too different, Lasso regression is the model to go forward with between the two, since it is able to capture important features. \n",
    "\n",
    "We now move towards the final model: Random Forest Regressor, since it has the capacity to model complicated relationships between the features and the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model 3: RF Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFModel = RandomForestRegressor(n_estimators=100,\n",
    "                                random_state= 42,\n",
    "                                n_jobs=-1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFModel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RFModel Model: Train Score = {:.2f}\".format(RFModel.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RFModel Model: Test Score = {:.2f}\".format(RFModel.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at residual plots and prediction vs actual plots for each of the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linreg = LinRegModel.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lasso = LassoModel.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = RFModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test,y_pred_linreg,marker='o');\n",
    "x = np.linspace(0,max(y_test));\n",
    "plt.plot(x,x,color = 'r');\n",
    "plt.xlabel('Actual Price');\n",
    "plt.ylabel('Predicted Price');\n",
    "plt.title('Linear Regression : Actual Vs Predicted Prices');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear Regression Model seems to underpredict larger prices (> 700)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test,y_pred_lasso,marker='o');\n",
    "x = np.linspace(0,max(y_test));\n",
    "plt.plot(x,x,color = 'r');\n",
    "plt.xlabel('Actual Price');\n",
    "plt.ylabel('Predicted Price');\n",
    "plt.title('Lasso Regression : Actual Vs Predicted Prices');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same is the case with Lasso model, where higher price properties are underpredicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test,y_pred_RF,marker='o');\n",
    "x = np.linspace(0,max(y_test));\n",
    "plt.plot(x,x,color = 'r');\n",
    "plt.xlabel('Actual Price');\n",
    "plt.ylabel('Predicted Price');\n",
    "plt.title('Random Forest Regression : Actual Vs Predicted Prices');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random forest model seems to be capturing all price listings well in its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at error plots for each of the 3 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test,(y_test - y_pred_linreg));\n",
    "plt.title('Residuals: Linear Regression');\n",
    "plt.xlabel('Actual Prices');\n",
    "plt.ylabel('Actual Price- Predicted Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual errors do have a pattern since higher actual price listings have higher errors as seen in the prediction plot above. Thus this model is not a good predictor for higher price listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test,(y_test - y_pred_lasso));\n",
    "plt.title('Residuals: Lasso Regression');\n",
    "plt.xlabel('Actual Prices');\n",
    "plt.ylabel('Actual Price- Predicted Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Linear Regression Residual plot, Lasso Regression residuals also increase linearly with higher actual prices, indicating the model's poor performance in that range of listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test,(y_test - y_pred_RF));\n",
    "plt.title('Residuals: Random Forest Regression');\n",
    "plt.xlabel('Actual Prices');\n",
    "plt.ylabel('Actual Price- Predicted Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Residuals plot here looks good with values having no pattern, as is required for a good residuals plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally look at the important features found by Random Forest Regressor Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureImportance = pd.DataFrame({\n",
    "        'Features' : X_train.columns,\n",
    "    'FeatureImportance' : RFModel.feature_importances_\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureImportance['FeatureImportance'] = dfFeatureImportance['FeatureImportance'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureImportance.sort_values(by=['FeatureImportance'],ascending=False).reset_index().drop(['index'],axis=1)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that we expected to be related to price determination are also deemed important by the Random Forest Regressor model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we looked at Seattle AirBnB data. \n",
    "\n",
    "We investigated a few questions through the available data:   \n",
    "    \n",
    "    1. How are the prices of properties distributed across the neighborhoods?\n",
    "    \n",
    "    2. Are there price variations within the year? Which months are most expensive and which are not?  \n",
    "    \n",
    "    3. Which are the important factors for determining the price of a property? Can we model this?   \n",
    "\n",
    "We did basic data wrangling to get the features we require from the data for the model.\n",
    "We then built a few models to estimate price for a listing given the features. Random Forest model did quite a good job in estimating the prices. \n",
    "\n",
    "Hope this gave some flavor in analysing the data through a CRISP-DM methodology. \n",
    "Cheers!\n",
    " \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
